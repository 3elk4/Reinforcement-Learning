# Reinforcement Learning & W.U.N.S.Z.

Project collaborates with another project named [W.U.N.S.Z.](https://github.com/3elk4/W.U.N.S.Z.).

This time, instead of algorithms, snakes uses simple Reinforcement Learning technics:
 - Markov Decission Process model
 - Q-Learning
 - SARSA
 - Approximate Q-Learning

![qlearningmaze](https://github.com/3elk4/Reinforcement-Learning/assets/33397049/146d30a9-397c-4cc1-b786-1f6976a45eb8)

Algorithms can be used in any type of maze, but it's not reccomended to build very big environments. These types of technics are mostly based on Q-table and large mazes can cause problems with efficiency and memory.

Some of gifs shows not only how snake is moving but alse Q-table of given environment.

### Markov Decision Process model:

![mdp](https://github.com/3elk4/Reinforcement-Learning/assets/33397049/e3470088-ffe4-4d92-832f-20172f427a6a)

### Q-Learning:

![qlearningh](https://github.com/3elk4/Reinforcement-Learning/assets/33397049/57a62e99-cee9-4bbb-8b2e-88e8b12f6ad6)

### SARSA:

![sarsah](https://github.com/3elk4/Reinforcement-Learning/assets/33397049/b75c8158-4c5f-45dc-a427-5d8f60fd0c50)

### Approximate Q-Learning:

![approxqlearning](https://github.com/3elk4/Reinforcement-Learning/assets/33397049/390aa52e-aee0-472f-bb0f-0cdbd101185b)

## Learning process

It is also possible to learn model on given environment with specific parameters.

| During Learning | After learning |
|-----------------|----------------|
|![qlearninglearning](https://github.com/3elk4/Reinforcement-Learning/assets/33397049/587aa15f-ccc9-41a9-8a20-5fbd65102869) | ![qlearninglearning2](https://github.com/3elk4/Reinforcement-Learning/assets/33397049/e4dfb6af-86dc-49f5-aa3c-540d5cfec0b2) |

It is possible to switch between technics and see the results of learning:

![srarsaqlearning](https://github.com/3elk4/Reinforcement-Learning/assets/33397049/94b786b3-a9a7-4905-b866-ec8d11219134)
